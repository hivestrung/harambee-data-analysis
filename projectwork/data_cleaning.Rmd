---
title: "iX Project - Shiv"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/shiv/Desktop/iX/ix_cape_town_2019_project")
library(tidyverse)
library(lubridate)
library(hablar)
library(caret)

```

Wiki: https://github.com/neilrankinza/ix_cape_town_2019_project/wiki

Build a machine learning model to:
1. Predict who is likely to be in work (in survey 1) so that they can intervene at ‘baseline’
2. Predict who is likely to work for more than 6 months

# Import the data
```{r, echo=FALSE}
data <- read_csv("data/raw/teaching_training_data.csv") %>% select(-X1)
cft <- read.csv("data/raw/teaching_training_data_cft.csv") %>% select(-X)
com <- read.csv("data/raw/teaching_training_data_com.csv") %>% select(-X)
grit <- read.csv("data/raw/teaching_training_data_grit.csv") %>% select(-X)
num <- read.csv("data/raw/teaching_training_data_num.csv") %>% select(-X)
opt <- read.csv("data/raw/teaching_training_data_opt.csv") %>% select(-X)
```

# Understand the data

```{r}
head(data)
head(cft)
head(com)
head(grit)
head(num)
head(opt)
```

```{r}
summary(data)
```

# Sort the data and rename unid to id, then order it such that id is in the front
```{r}
data = arrange(data, unid)
data = mutate(data, id = unid) %>% select(-unid)
data = data[, c(dim(data)[2], 1:dim(data)[2]-1)]

```
# Split into work and no work groups

```{r}
data.work = data %>% filter(working==T) %>% select(-working)
data.nowork = data %>% filter(working==F)
```

# Cleanup

## Handling NAs in job_start_date and/or job_leave_date

1. If job_start_date is NA, remove row
```{r, echo=FALSE}
data.work = data.work %>% filter(!is.na(job_start_date))
```
At this point, all rows have a valid job_start_date

2. If job_leave_date is NA, we assume he is still working at the date of survey, hence replace job_leave_date with survey_date_month
```{r}
data.work$job_leave_date = as_date(ifelse(is.na(data.work$job_leave_date), data.work$survey_date_month, data.work$job_leave_date))
```

## Parsing peoplelive column

```{r}
data.work <- data.work %>%
 mutate(fin_situ_now = parse_number(as.character(financial_situation_now))) %>%
 mutate(fin_situ_future = parse_number(as.character(financial_situation_5years))) %>%
 mutate(fin_situ_change = fin_situ_future - fin_situ_now)
```




# Feature Engineering

1. Based on job_start_date and job_leave_date, create a column daysWorked, which gives the number of days worked
```{r}
data.work$daysWorked = as.Date(as.character(data.work$job_leave_date), format="%Y-%m-%d")-
                  as.Date(as.character(data.work$job_start_date), format="%Y-%m-%d") + 1
```
2. Based on daysWorked, create a column modeThanSixMths indicating whether the person has worked more than 6 months
```{r}
data.work$moreThanSixMths = ifelse(data.work$daysWorked >= 180, T, F)
```

3. Based on date of birth (dob) and survey_date_month, create column age_at_survey (and round to the nearest integer)
```{r}
data.work <- data.work %>%
 mutate(age_at_survey = interval(dob, survey_date_month)/years(1)) %>%
 mutate(age_at_survey = round(age_at_survey))
```

4. Parse the text from the financial situation columns, and create a column fin_situ_change that gives us the expected change in financial situation

```{r}
data.work <- data.work %>%
 mutate(fin_situ_now = parse_number(as.character(financial_situation_now))) %>%
 mutate(fin_situ_future = parse_number(as.character(financial_situation_5years))) %>%
 mutate(fin_situ_change = fin_situ_future - fin_situ_now)
```

Finally, let's remove the redundant data we've already used to engineer features
```{r}
data.work = data.work %>% select(-job_start_date ,-job_leave_date, -dob, -financial_situation_now, -financial_situation_5years)
```

# Working with incomplete data

Check the number of NAs in every column, and calculate percentage of na's in column

```{r}
na_count = sapply(data.work, function(y) sum(length(which(is.na(y)))))
na_count = data.frame(na_count)
dim(na_count)

# create column from index
names <- rownames(na_count)
# nullify index
rownames(na_count) <- NULL
na_count <- cbind(names,na_count)

na_count = mutate(na_count, percentageNA = na_count/dim(data.work)[1])
na_count = arrange(na_count, desc(percentageNA))
na_count
```
As we can see, company_size and monthly_pay are about 90% NAs. However, these are likely very important in determining whether a person is likely to stay at their job (for instance, if you're paid well, you're incentivised to stay on and work hard.) So, we will want to impute the data for this.

First, we'll fill in the rest of the columns, making some assumptions along the way.

data.work$peoplelive

assume

impute

remove







## CLeaning the extra data (from the personality attribute tests)
After some exploration, we realised only opt has NAs

Clean opt because it has NAs
```{r}
opt = na.omit(opt)
```

Grit has multiple readings per individual, visualising this, which plots a graph of number of people against how many grit readings they have

```{r}
grit_analysis  = group_by(grit, unid) %>% count() %>% group_by(n) %>% count()
ggplot(grit_analysis, aes(x=n,y=nn)) + geom_bar(stat="identity") + xlab("Number of grit readings") + ylab("Number of people") + scale_x_continuous(breaks = round(seq(min(grit_analysis$n), max(grit_analysis$n), by =1),1))
```


```{r}
opt_analysis  = group_by(opt, unid) %>% count() %>% group_by(n) %>% count()
ggplot(opt_analysis, aes(x=n,y=nn)) + geom_bar(stat="identity") + xlab("Number of opt readings") + ylab("Number of people") + scale_x_continuous(breaks = round(seq(min(opt_analysis$n), max(opt_analysis$n), by =1),1)) 
```

```{r}
com_analysis  = group_by(com, unid) %>% count() %>% group_by(n) %>% count()
ggplot(com_analysis, aes(x=n,y=nn)) + geom_bar(stat="identity") + xlab("Number of com readings") + ylab("Number of people") + scale_x_continuous(breaks = round(seq(min(com_analysis$n), max(com_analysis$n), by =1),1))
```


```{r}
cft_analysis  = group_by(cft, unid) %>% count() %>% group_by(n) %>% count()
ggplot(cft_analysis, aes(x=n,y=nn)) + geom_bar(stat="identity") + xlab("Number of cft readings") + ylab("Number of people") + scale_x_continuous(breaks = round(seq(min(cft_analysis$n), max(cft_analysis$n), by =1),1))
```

```{r}
num_analysis  = group_by(num, unid) %>% count() %>% group_by(n) %>% count()
ggplot(num_analysis, aes(x=n,y=nn)) + geom_bar(stat="identity") + xlab("Number of num readings") + ylab("Number of people") + scale_x_continuous(breaks = round(seq(min(num_analysis$n), max(num_analysis$n), by =1),1))
```

We will just take the mean to break ties

```{r}
grit_clean = group_by(grit,unid)  %>% summarise(mean_grit_score=mean(grit_score))
grit_clean$mean_grit_score = round(grit_clean$mean_grit_score)

com_clean = group_by(com,unid)  %>% summarise(mean_com_score=mean(com_score))
com_clean$mean_com_score = round(com_clean$mean_com_score)

opt_clean = group_by(opt,unid)  %>% summarise(mean_opt_score=mean(opt_score))
opt_clean$mean_opt_score = round(opt_clean$mean_opt_score)

cft_clean = group_by(cft,unid)  %>% summarise(mean_cft_score=mean(cft_score))
cft_clean$mean_cft_score = round(cft_clean$mean_cft_score)

num_clean = group_by(num,unid)  %>% summarise(mean_num_score=mean(num_score))
num_clean$mean_num_score = round(num_clean$mean_num_score)
```


merging the datasets
```{r}
data.work.clean.merged = data.work.clean %>% merge(opt_clean, by="unid", all.x=T) %>% merge(num_clean, by="unid", all.x=T) %>% merge(grit_clean,by="unid", all.x=T) %>% merge(cft_clean, by="unid", all.x=T) %>% merge(com_clean, by="unid", all.x=T)

str(data.work.clean.merged)

```


Assuming that if NA, volunteer is no, leadershiprole is no, peoplelive is 0, peoplelive_15plus is 0, numchildren is 0, numearnincome is 0

inspect the data for useless columns (firstly, remove columns with v little data)

```{r}
summary(data.work.clean.merged)
```


clean the data of nas

```{r}
data.work.clean3 = na.omit(data.work.clean2)
```






Finalising the dataset
```{r}
data.work.final = select(data.work.clean.merged, -survey_date_month, -fin_situ_change,     -survey_num, -unid)

```
## viewing the data

```{r}
ggplot(data.work.final, aes(y=moreThanSixMths,x=gender)) + 
```



## performing logistic regression


```{r}
data.work.final$moreThanSixMths =  as.factor(data.work.final$moreThanSixMths)

TRAINCONTROL = trainControl(method = "cv", number = 8, verboseIter = TRUE)

glm_model <- train(moreThanSixMths~., data = data.work.final, method = "rpart", trControl = TRAINCONTROL)
glm_model

```

















